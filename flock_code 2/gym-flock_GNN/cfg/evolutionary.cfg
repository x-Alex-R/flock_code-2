[DEFAULT]

# Specify that we wish to use the evolutionary algorithm defined in
# ``learner/evolutionary/evo_trainer.py``.
alg = evolutionary

##############################
# Environment parameters
##############################

# FlockingLeader-v0 is registered by gym_flock in __init__.py and encapsulates a
# leader-following flocking task.
env = FlockingLeader-v0

# Maximum velocity for each agent
v_max = 3.0

# Communication radius controlling which neighbours each agent can observe
comm_radius = 2.0

# Number of agents and leaders in the environment.  Only the non-leader agents
# are controlled by the learned policy.
n_agents = 100
n_leaders = 3

# Simulation time step
dt = 0.01

##############################
# Evolutionary algorithm hyperparameters
##############################

# Seed for reproducibility
seed = 1

# Population size used by the evolutionary algorithm.  Larger populations
# provide more diverse policies but increase computational cost.
pop_size = 30

# Fraction of the top-performing individuals preserved as elites at each
# generation.
elite_frac = 0.2

# Standard deviation of the Gaussian noise added during mutation.  This
# controls how aggressively policies explore new behaviours.
mutation_sigma = 0.05

# Number of generations to evolve for.  Each generation evaluates the
# fitness of the entire population.
generations = 80

# Length of each episode (number of time steps) used when evaluating fitness.
episode_len = 100

##############################
# Neural network architecture
##############################

# Sizes of the hidden layers in the actor network.  The number of inputs and
# outputs is determined at runtime based on the environment state and action
# dimensions.
hidden_layers = [64, 64]

# Number of previous graph convolutional steps used by the GNN (history length).
k = 3

# Aggregation method for message passing (1=mean, 0=sum)
ind_agg = 1